{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-25T02:28:08.129225Z","iopub.execute_input":"2022-04-25T02:28:08.131334Z","iopub.status.idle":"2022-04-25T02:28:08.166441Z","shell.execute_reply.started":"2022-04-25T02:28:08.130102Z","shell.execute_reply":"2022-04-25T02:28:08.165839Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport calendar\nfrom datetime import datetime, date\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Patch\nfrom matplotlib.ticker import MaxNLocator\n\nimport seaborn as sns\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nimport plotly.offline as offline\nimport plotly.graph_objs as go\noffline.init_notebook_mode(connected = True)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:08.167963Z","iopub.execute_input":"2022-04-25T02:28:08.168414Z","iopub.status.idle":"2022-04-25T02:28:11.720938Z","shell.execute_reply.started":"2022-04-25T02:28:08.168372Z","shell.execute_reply":"2022-04-25T02:28:11.719896Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## **Data**","metadata":{}},{"cell_type":"code","source":"df_holi = pd.read_csv('../input/store-sales-time-series-forecasting/holidays_events.csv',parse_dates=['date'])\ndf_oil = pd.read_csv('../input/store-sales-time-series-forecasting/oil.csv',parse_dates=['date'])\ndf_stores = pd.read_csv('../input/store-sales-time-series-forecasting/stores.csv')\ndf_trans = pd.read_csv('../input/store-sales-time-series-forecasting/transactions.csv',parse_dates=['date'])\n\ndf_train = pd.read_csv('../input/store-sales-time-series-forecasting/train.csv',parse_dates=['date'])\ndf_test = pd.read_csv('../input/store-sales-time-series-forecasting/test.csv',parse_dates=['date'])","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:11.722521Z","iopub.execute_input":"2022-04-25T02:28:11.722778Z","iopub.status.idle":"2022-04-25T02:28:15.571536Z","shell.execute_reply.started":"2022-04-25T02:28:11.722750Z","shell.execute_reply":"2022-04-25T02:28:15.570817Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## **Merging Data**","metadata":{}},{"cell_type":"code","source":"# Merging other data with TRAIN Data\ndf_train1 = df_train.merge(df_holi, on = 'date', how='left')\ndf_train1 = df_train1.merge(df_oil, on = 'date', how='left')\ndf_train1 = df_train1.merge(df_stores, on = 'store_nbr', how='left')\ndf_train1 = df_train1.merge(df_trans, on = ['date','store_nbr'], how='left')\ndf_train1 = df_train1.rename(columns = {\"type_x\" : \"holiday_type\", \"type_y\" : \"store_type\"})\n\ndf_train1['date'] = pd.to_datetime(df_train1['date'])\ndf_train1['year'] = df_train1['date'].dt.year\ndf_train1['month'] = df_train1['date'].dt.month\ndf_train1['week'] = df_train1['date'].dt.isocalendar().week\ndf_train1['quarter'] = df_train1['date'].dt.quarter\ndf_train1['day_of_week'] = df_train1['date'].dt.day_name()\n\n# Merging other data with TEST Data\ndf_test1 = df_test.merge(df_holi, on = 'date', how='left')\ndf_test1 = df_test1.merge(df_oil, on = 'date', how='left')\ndf_test1 = df_test1.merge(df_stores, on = 'store_nbr', how='left')\ndf_test1 = df_test1.merge(df_trans, on =['date','store_nbr'], how='left')\ndf_test1 = df_test1.rename(columns = {\"type_x\" : \"holiday_type\", \"type_y\" : \"store_type\"})\n\ndf_test1['date'] = pd.to_datetime(df_test1['date'])\ndf_test1['year'] = df_test1['date'].dt.year\ndf_test1['month'] = df_test1['date'].dt.month\ndf_test1['week'] = df_test1['date'].dt.isocalendar().week\ndf_test1['quarter'] = df_test1['date'].dt.quarter\ndf_test1['day_of_week'] = df_test1['date'].dt.day_name()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:15.573272Z","iopub.execute_input":"2022-04-25T02:28:15.573511Z","iopub.status.idle":"2022-04-25T02:28:23.096480Z","shell.execute_reply.started":"2022-04-25T02:28:15.573484Z","shell.execute_reply":"2022-04-25T02:28:23.095643Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"total_records = df_train1.shape[0]\nfirst_date    = df_train1.date.iloc[0]\nlast_date     = df_train1.date.iloc[-1]\ntotal_days    = (df_train1.date.iloc[-1] - df_train1.date.iloc[0]).days\nstore_nbr_id  = df_stores.index.values # stores_data.store_nbr.unique()\nfamily_unique = df_train1.family.unique()\n\nprint(\"### Number of Records\")\nprint( \"{} from {} to {}\".format(total_records,first_date.to_period(\"D\"), last_date.to_period(\"D\") ) )\nprint( \"(Total of {} days or {} months)\".format(total_days,total_days//30 ) ) \nprint(\"### Number of Stores\")\nprint( \"{} stores\".format(len(store_nbr_id) ) )\nprint(\"### Number of Product Family\")\nprint( \"{} types\".format(len(family_unique) ) )\nprint(\"### Number of Cities and States\")\nprint( \"{} cities in {} states\". format(len(df_stores.city.unique()), len(df_stores.state.unique()) )  )\n# print( [stores_data.loc[store]['city'] for store in stores_data.index] )","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:23.097915Z","iopub.execute_input":"2022-04-25T02:28:23.098130Z","iopub.status.idle":"2022-04-25T02:28:23.360414Z","shell.execute_reply.started":"2022-04-25T02:28:23.098104Z","shell.execute_reply":"2022-04-25T02:28:23.359580Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## **Sales Analysis**","metadata":{}},{"cell_type":"markdown","source":"### **Store Sales by City**","metadata":{}},{"cell_type":"code","source":"top_city  = df_stores.groupby('city') .size().sort_values(ascending=False)\ntop_state = df_stores.groupby('state').size().sort_values(ascending=False)\nstates = top_state.index.values\n\nstores_data_grouped = df_stores.groupby(['state','city']).agg({'city':'count'})\ncolor = [\"tab:red\",\"tab:orange\",\"tab:brown\",\"tab:cyan\",\"tab:green\",\"tab:purple\",\"tab:blue\",\"tab:gray\",\"tab:pink\", \"navy\",\"darkred\"]\nfig, ax = plt.subplots( figsize=(16,5))\nax.yaxis.set_major_locator(MaxNLocator(integer=True))\nax.set_title(\"Distribution of Store by City and State\")\nax.set_ylabel(\"Number of stores\")\nax.set_xlabel(\"City\")\ncustom_label=[]\ncustom_legend = []\nfor i in range(0,10):\n    u = stores_data_grouped.loc[ states[i] ]\n    ax.bar(u.index.values, u.values.flatten(),color=color[i])\n    custom_label.append ( Patch(facecolor=color[i])  )\n    custom_legend.append( states[i] + \" (Total {})\".format(top_state[i]))\nax.legend(custom_label, custom_legend, fontsize=\"large\", labelcolor=\"black\", \n          fancybox=True, title = \"States\", title_fontsize = \"x-large\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:23.362173Z","iopub.execute_input":"2022-04-25T02:28:23.362481Z","iopub.status.idle":"2022-04-25T02:28:23.740228Z","shell.execute_reply.started":"2022-04-25T02:28:23.362441Z","shell.execute_reply":"2022-04-25T02:28:23.739247Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### **Store Sales by State**","metadata":{}},{"cell_type":"code","source":"sales_grouped  = df_train.groupby('date').agg({'sales':'sum'}).to_period(\"D\")\nsales_grouped['year']      = sales_grouped.index.year\nsales_grouped['quarter']   = sales_grouped.index.quarter\nsales_grouped['month']     = sales_grouped.index.month\nsales_grouped['week']      = sales_grouped.index.week\nsales_grouped['dayofweek'] = sales_grouped.index.dayofweek  # Monday=0, Sunday=6\nsales_grouped['dayofmonth']= sales_grouped.index.day  # day in month from 01 to 31\nsales_grouped['dayofyear'] = sales_grouped.index.dayofyear\n\nsales_smooth7  = sales_grouped.copy()\nsales_smooth30 = sales_grouped.copy()\nsales_smooth365= sales_grouped.copy()\n\nsales_smooth7[\"sales\"]   = sales_smooth7.  sales.rolling(window=7,  center=True, min_periods=3 ).mean()\nsales_smooth30[\"sales\"]  = sales_smooth30. sales.rolling(window=30, center=True, min_periods=15).mean()\nsales_smooth365[\"sales\"] = sales_smooth365.sales.rolling(window=365,center=True, min_periods=183).mean()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:23.741564Z","iopub.execute_input":"2022-04-25T02:28:23.741813Z","iopub.status.idle":"2022-04-25T02:28:23.824021Z","shell.execute_reply.started":"2022-04-25T02:28:23.741786Z","shell.execute_reply":"2022-04-25T02:28:23.823007Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### **Product-Wise Sales**","metadata":{}},{"cell_type":"code","source":"# data\ndf_st_sa = df_train1.groupby('store_type').agg({\"sales\" : \"mean\"}).reset_index().sort_values(by='sales', ascending=False)\ndf_fa_sa = df_train1.groupby('family').agg({\"sales\" : \"mean\"}).reset_index().sort_values(by='sales', ascending=False)[:10]\ndf_cl_sa = df_train1.groupby('cluster').agg({\"sales\" : \"mean\"}).reset_index() \n# chart color\ndf_fa_sa['color'] = '#496595'\ndf_fa_sa['color'][2:] = '#c6ccd8'\ndf_cl_sa['color'] = '#c6ccd8'\n\n# chart\nfig = make_subplots(rows=2, cols=2, \n                    specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}],\n                           [{\"colspan\": 2}, None]],\n                    column_widths=[0.7, 0.3], vertical_spacing=0, horizontal_spacing=0.02,\n                    subplot_titles=(\"Top 10 Highest Product Sales\", \"Highest Sales in Stores\", \"Clusters Vs Sales\"))\n\nfig.add_trace(go.Bar(x=df_fa_sa['sales'], y=df_fa_sa['family'], marker=dict(color= df_fa_sa['color']),\n                     name='Family', orientation='h'), \n                     row=1, col=1)\nfig.add_trace(go.Pie(values=df_st_sa['sales'], labels=df_st_sa['store_type'], name='Store type',\n                     marker=dict(colors=['#334668','#496595','#6D83AA','#91A2BF','#C8D0DF']), hole=0.7,\n                     hoverinfo='label+percent+value', textinfo='label'), \n                    row=1, col=2)\nfig.add_trace(go.Bar(x=df_cl_sa['cluster'], y=df_cl_sa['sales'], \n                     marker=dict(color= df_cl_sa['color']), name='Cluster'), \n                     row=2, col=1)\n\n# styling\nfig.update_yaxes(showgrid=False, ticksuffix=' ', categoryorder='total ascending', row=1, col=1)\nfig.update_xaxes(visible=False, row=1, col=1)\nfig.update_xaxes(tickmode = 'array', tickvals=df_cl_sa.cluster, ticktext=[i for i in range(1,17)], row=2, col=1)\nfig.update_yaxes(visible=False, row=2, col=1)\nfig.update_layout(height=500, bargap=0.2,\n                  margin=dict(b=0,r=20,l=20), xaxis=dict(tickmode='linear'),\n                  title_text=\"Average Sales Analysis\",\n                  template=\"plotly_white\",\n                  title_font=dict(size=29, color='#8a8d93', family=\"Lato, sans-serif\"),\n                  font=dict(color='#8a8d93'), \n                  hoverlabel=dict(bgcolor=\"#f2f2f2\", font_size=13, font_family=\"Lato, sans-serif\"),\n                  showlegend=False)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:23.825619Z","iopub.execute_input":"2022-04-25T02:28:23.825938Z","iopub.status.idle":"2022-04-25T02:28:25.477433Z","shell.execute_reply.started":"2022-04-25T02:28:23.825897Z","shell.execute_reply":"2022-04-25T02:28:25.476634Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Interpret**\n\nHighest sales are made by the products like grocery and beverages.\nStore A has the highest sales which is 38%","metadata":{}},{"cell_type":"markdown","source":"### **Year-Month-Wise Sales**","metadata":{}},{"cell_type":"code","source":"# data \ndf_2013 = df_train1[df_train1['year']==2013][['month','sales']]\ndf_2013 = df_2013.groupby('month').agg({\"sales\" : \"mean\"}).reset_index().rename(columns={'sales':'s13'})\ndf_2014 = df_train1[df_train1['year']==2014][['month','sales']]\ndf_2014 = df_2014.groupby('month').agg({\"sales\" : \"mean\"}).reset_index().rename(columns={'sales':'s14'})\ndf_2015 = df_train1[df_train1['year']==2015][['month','sales']]\ndf_2015 = df_2015.groupby('month').agg({\"sales\" : \"mean\"}).reset_index().rename(columns={'sales':'s15'})\ndf_2016 = df_train1[df_train1['year']==2016][['month','sales']]\ndf_2016 = df_2016.groupby('month').agg({\"sales\" : \"mean\"}).reset_index().rename(columns={'sales':'s16'})\ndf_2017 = df_train1[df_train1['year']==2017][['month','sales']]\ndf_2017 = df_2017.groupby('month').agg({\"sales\" : \"mean\"}).reset_index()\ndf_2017_no = pd.DataFrame({'month': [9,10,11,12], 'sales':[0,0,0,0]})\ndf_2017 = df_2017.append(df_2017_no).rename(columns={'sales':'s17'})\ndf_year = df_2013.merge(df_2014,on='month').merge(df_2015,on='month').merge(df_2016,on='month').merge(df_2017,on='month')\n\n# top levels\ntop_labels = ['2013', '2014', '2015', '2016', '2017']\n\ncolors = ['rgba(38, 24, 74, 0.8)', 'rgba(71, 58, 131, 0.8)',\n          'rgba(122, 120, 168, 0.8)', 'rgba(164, 163, 204, 0.85)',\n          'rgba(190, 192, 213, 1)']\n\n# X axis value \ndf_year = df_year[['s13','s14','s15','s16','s17']].replace(np.nan,0)\nx_data = df_year.values\n\n# y axis value (Month)\ndf_2013['month'] =['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\ny_data = df_2013['month'].tolist()\n\nfig = go.Figure()\nfor i in range(0, len(x_data[0])):\n    for xd, yd in zip(x_data, y_data):\n        fig.add_trace(go.Bar(\n            x=[xd[i]], y=[yd],\n            orientation='h',\n            marker=dict(\n                color=colors[i],\n                line=dict(color='rgb(248, 248, 249)', width=1)\n            )\n        ))\n\nfig.update_layout(title='Avg Sales for each Year',\n    xaxis=dict(showgrid=False, \n               zeroline=False, domain=[0.15, 1]),\n    yaxis=dict(showgrid=False, showline=False,\n               showticklabels=False, zeroline=False),\n    barmode='stack', \n    template=\"plotly_white\",\n    margin=dict(l=0, r=50, t=100, b=10),\n    showlegend=False, \n)\n\nannotations = []\nfor yd, xd in zip(y_data, x_data):\n    # labeling the y-axis\n    annotations.append(dict(xref='paper', yref='y',\n                            x=0.14, y=yd,\n                            xanchor='right',\n                            text=str(yd),\n                            font=dict(family='Arial', size=14,\n                                      color='rgb(67, 67, 67)'),\n                            showarrow=False, align='right'))\n    # labeling the first Likert scale (on the top)\n    if yd == y_data[-1]:\n        annotations.append(dict(xref='x', yref='paper',\n                                x=xd[0] / 2, y=1.1,\n                                text=top_labels[0],\n                                font=dict(family='Arial', size=14,\n                                          color='rgb(67, 67, 67)'),\n                          showarrow=False))\n    space = xd[0]\n    for i in range(1, len(xd)):\n            # labeling the Likert scale\n            if yd == y_data[-1]:\n                annotations.append(dict(xref='x', yref='paper',\n                                        x=space + (xd[i]/2), y=1.1,\n                                        text=top_labels[i],\n                                        font=dict(family='Arial', size=14,\n                                                  color='rgb(67, 67, 67)'),\n                                        showarrow=False))\n            space += xd[i]\n            fig.update_layout(\n    annotations=annotations)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:25.480197Z","iopub.execute_input":"2022-04-25T02:28:25.480429Z","iopub.status.idle":"2022-04-25T02:28:28.534300Z","shell.execute_reply.started":"2022-04-25T02:28:25.480402Z","shell.execute_reply":"2022-04-25T02:28:28.533299Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**Interpret**\n\nHighest sales are made in December month and then decreases in January.\nSales are increasing gradually from 2013 to 2017.\nNote: We don't have data for 2017: 9th to 12th month.","metadata":{}},{"cell_type":"markdown","source":"### **Month-Wise Sales**","metadata":{}},{"cell_type":"code","source":"# data\ndf_m_sa = df_train1.groupby('month').agg({\"sales\" : \"mean\"}).reset_index()\ndf_m_sa['sales'] = round(df_m_sa['sales'],2)\ndf_m_sa['month_text'] = df_m_sa['month'].apply(lambda x: calendar.month_abbr[x])\ndf_m_sa['text'] = df_m_sa['month_text'] + ' - ' + df_m_sa['sales'].astype(str) \n\ndf_w_sa = df_train1.groupby('week').agg({\"sales\" : \"mean\"}).reset_index() \ndf_q_sa = df_train1.groupby('quarter').agg({\"sales\" : \"mean\"}).reset_index() \n# chart color\ndf_m_sa['color'] = '#496595'\ndf_m_sa['color'][:-1] = '#c6ccd8'\ndf_w_sa['color'] = '#c6ccd8'\n\n# chart\nfig = make_subplots(rows=2, cols=2, vertical_spacing=0.08,\n                    row_heights=[0.7, 0.3], \n                    specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}],\n                           [{\"colspan\": 2}, None]],\n                    column_widths=[0.7, 0.3],\n                    subplot_titles=(\"Month wise Avg Sales Analysis\", \"Quarter wise Avg Sales Analysis\", \n                                    \"Week wise Avg Sales Analysis\"))\n\nfig.add_trace(go.Bar(x=df_m_sa['sales'], y=df_m_sa['month'], marker=dict(color= df_m_sa['color']),\n                     text=df_m_sa['text'],textposition='auto',\n                     name='Month', orientation='h'), \n                     row=1, col=1)\nfig.add_trace(go.Pie(values=df_q_sa['sales'], labels=df_q_sa['quarter'], name='Quarter',\n                     marker=dict(colors=['#334668','#496595','#6D83AA','#91A2BF','#C8D0DF']), hole=0.7,\n                     hoverinfo='label+percent+value', textinfo='label+percent'), \n                     row=1, col=2)\nfig.add_trace(go.Scatter(x=df_w_sa['week'], y=df_w_sa['sales'], mode='lines+markers', fill='tozeroy', fillcolor='#c6ccd8',\n                     marker=dict(color= '#496595'), name='Week'), \n                     row=2, col=1)\n\n# styling\nfig.update_yaxes(visible=False, row=1, col=1)\nfig.update_xaxes(visible=False, row=1, col=1)\nfig.update_xaxes(tickmode = 'array', tickvals=df_w_sa.week, ticktext=[i for i in range(1,53)], \n                 row=2, col=1)\nfig.update_yaxes(visible=False, row=2, col=1)\nfig.update_layout(height=750, bargap=0.15,\n                  margin=dict(b=0,r=20,l=20), \n                  title_text=\"Average Sales Analysis\",\n                  template=\"plotly_white\",\n                  title_font=dict(size=25, color='#8a8d93', family=\"Lato, sans-serif\"),\n                  font=dict(color='#8a8d93'),\n                  hoverlabel=dict(bgcolor=\"#f2f2f2\", font_size=13, font_family=\"Lato, sans-serif\"),\n                  showlegend=False)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:28.536121Z","iopub.execute_input":"2022-04-25T02:28:28.536454Z","iopub.status.idle":"2022-04-25T02:28:28.816772Z","shell.execute_reply.started":"2022-04-25T02:28:28.536411Z","shell.execute_reply":"2022-04-25T02:28:28.815953Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### **Day-Wise Sales**","metadata":{}},{"cell_type":"code","source":"# data\ndf_dw_sa = df_train1.groupby('day_of_week').agg({\"sales\" : \"mean\"}).reset_index()\ndf_dw_sa.sales = round(df_dw_sa.sales, 2)\n\n# chart\nfig = px.bar(df_dw_sa, y='day_of_week', x='sales', title='Avg Sales vs Day of Week',\n             color_discrete_sequence=['#c6ccd8'], text='sales',\n             category_orders=dict(day_of_week=[\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\", \"Friday\",\"Saturday\",\"Sunday\"]))\nfig.update_yaxes(showgrid=False, ticksuffix=' ', showline=False)\nfig.update_xaxes(visible=False)\nfig.update_layout(margin=dict(t=60, b=0, l=0, r=0), height=350,\n                  hovermode=\"y unified\", \n                  yaxis_title=\" \", template='plotly_white',\n                  title_font=dict(size=25, color='#8a8d93', family=\"Lato, sans-serif\"),\n                  font=dict(color='#8a8d93'),\n                  hoverlabel=dict(bgcolor=\"#c6ccd8\", font_size=13, font_family=\"Lato, sans-serif\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:28.818344Z","iopub.execute_input":"2022-04-25T02:28:28.818817Z","iopub.status.idle":"2022-04-25T02:28:29.236360Z","shell.execute_reply.started":"2022-04-25T02:28:28.818775Z","shell.execute_reply":"2022-04-25T02:28:29.235745Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Interpret**\n\nAs we saw in the above chart there is an upward trend in sales over the time. Although there are ups and downs at every point in time, generally we can observe that the trend increases. Also we can notice how the ups and downs seem to be a bit regular, it means we might be observing a seasonal pattern here too. Let’s take a closer look by observing some year’s data:\nHighest sales are made on Sunday.\nDecember month has the highest sales.\nNote: We don't have data for 2017: 9th to 12th month.","metadata":{}},{"cell_type":"markdown","source":"### **Sales Store-Holiday-Wise**","metadata":{}},{"cell_type":"code","source":"# data\ndf_st_ht = df_train1.groupby(['store_type','holiday_type']).agg({\"sales\" : \"mean\"}).reset_index()\ndf_st_ht['sales'] = round(df_st_ht['sales'], 2)\n\n# chart\nfig = px.scatter(df_st_ht, x='store_type', color='sales', y='holiday_type', size='sales',\n                 color_discrete_sequence=px.colors.qualitative.D3,\n                 title=\"Average Sales: Store Type Vs Holiday Type\")\n# styling\nfig.update_yaxes(ticksuffix='  ')\nfig.update_layout(height=400, xaxis_title='', yaxis_title='',\n                  margin=dict(b=0),\n                  plot_bgcolor='#fafafa', paper_bgcolor='#fafafa',\n                  title_font=dict(size=29, color='#444', family=\"Lato, sans-serif\"),\n                  font=dict(color='#555'), \n                  hoverlabel=dict(bgcolor=\"#f2f2f2\", font_size=13, font_family=\"Lato, sans-serif\"))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:29.237494Z","iopub.execute_input":"2022-04-25T02:28:29.237851Z","iopub.status.idle":"2022-04-25T02:28:29.930916Z","shell.execute_reply.started":"2022-04-25T02:28:29.237823Z","shell.execute_reply":"2022-04-25T02:28:29.929986Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### **Sales Store-Year-Wise**","metadata":{}},{"cell_type":"code","source":"# data\ndf_y_m_st = df_train1.groupby(['year','month','store_type']).agg({\"sales\" : \"mean\"}).reset_index()\ndf_y_m_st['sales'] = round(df_y_m_st['sales'], 2)\n\n# chart\nfig = px.scatter(df_y_m_st, x='month', y='store_type', color='sales', size='sales', \n                 facet_row='year', title='Average Sales: Store Type Vs Year(Month)')\n# styling\nfig.update_yaxes(ticksuffix='  ')\nfig.update_xaxes(tickmode = 'array', tickvals=[i for i in range(1,13)], \n                 ticktext=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\nfig.update_layout(height=900, xaxis_title='', yaxis_title='',\n                  margin=dict(t=70, b=0),\n                  plot_bgcolor='#fafafa', paper_bgcolor='#fafafa',\n                  title_font=dict(size=29, color='#444', family=\"Lato, sans-serif\"),\n                  font=dict(color='#555'), \n                  hoverlabel=dict(bgcolor=\"#f2f2f2\", font_size=13, font_family=\"Lato, sans-serif\"))\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:29.932282Z","iopub.execute_input":"2022-04-25T02:28:29.932503Z","iopub.status.idle":"2022-04-25T02:28:30.508562Z","shell.execute_reply.started":"2022-04-25T02:28:29.932477Z","shell.execute_reply":"2022-04-25T02:28:30.507780Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### **Sales Month-Holiday-Wise**","metadata":{}},{"cell_type":"code","source":"# data\ndf_m_ht = df_train1.groupby(['month','holiday_type']).agg({\"sales\" : \"mean\"}).reset_index()\ndf_m_ht['sales'] = round(df_m_ht['sales'], 2)\n\n# chart\nfig = px.scatter(df_m_ht, x='month', color='sales', y='holiday_type', size='sales',\n                 color_discrete_sequence=px.colors.qualitative.D3,\n                 title=\"Average Sales: Month Vs Holiday Type\")\n# styling\nfig.update_yaxes(ticksuffix='  ')\nfig.update_xaxes(tickmode = 'array', tickvals=[i for i in range(1,13)], \n                 ticktext=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\nfig.update_layout(height=400, xaxis_title='', yaxis_title='',\n                  margin=dict(b=0),\n                  plot_bgcolor='#fafafa', paper_bgcolor='#fafafa',\n                  title_font=dict(size=29, color='#444', family=\"Lato, sans-serif\"),\n                  font=dict(color='#555'), \n                  hoverlabel=dict(bgcolor=\"#f2f2f2\", font_size=13, font_family=\"Lato, sans-serif\"))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:30.509821Z","iopub.execute_input":"2022-04-25T02:28:30.510419Z","iopub.status.idle":"2022-04-25T02:28:30.976635Z","shell.execute_reply.started":"2022-04-25T02:28:30.510375Z","shell.execute_reply":"2022-04-25T02:28:30.975760Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# data\ndf_y_m_ht = df_train1.groupby(['year','month','holiday_type']).agg({\"sales\" : \"mean\"}).reset_index()\ndf_y_m_ht['sales'] = round(df_y_m_ht['sales'], 2)\n\n# chart\nfig = px.scatter(df_y_m_ht, x='month', y='holiday_type', color='sales', size='sales', \n                 facet_row='year', title='Average Sales: Holiday_type Vs Year(Month)')\n# styling\nfig.update_yaxes(ticksuffix='  ')\nfig.update_xaxes(tickmode = 'array', tickvals=[i for i in range(1,13)], \n                 ticktext=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\nfig.update_layout(height=900, xaxis_title='', yaxis_title='',\n                  margin=dict(t=70, b=0),\n                  plot_bgcolor='#fafafa', paper_bgcolor='#fafafa',\n                  title_font=dict(size=29, color='#444', family=\"Lato, sans-serif\"),\n                  font=dict(color='#555'), \n                  hoverlabel=dict(bgcolor=\"#f2f2f2\", font_size=13, font_family=\"Lato, sans-serif\"))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:30.978006Z","iopub.execute_input":"2022-04-25T02:28:30.979118Z","iopub.status.idle":"2022-04-25T02:28:31.611014Z","shell.execute_reply.started":"2022-04-25T02:28:30.979062Z","shell.execute_reply":"2022-04-25T02:28:31.609905Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## **Correlations among stores**","metadata":{}},{"cell_type":"code","source":"##### Find Correlations among stores ########\na = df_train1[[\"store_nbr\", \"sales\"]]\n# Create another column to index sales for each store by day by family\na[\"ind\"] = 1\na[\"ind\"] = a.groupby(\"store_nbr\").ind.cumsum().values\na = pd.pivot(a, index = \"ind\", columns = \"store_nbr\", values = \"sales\").corr()\nmask = np.triu(a) # Create upper triangle to hide in heatmap\n\n# Plot a heat map\nplt.figure(figsize=(15, 15))\nsns.heatmap(a, annot=True, fmt='.1f', cmap='bwr', square=True, mask=mask, linewidths=1, cbar=False)\nplt.title(\"Correlations among stores\",fontsize = 16)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:31.612503Z","iopub.execute_input":"2022-04-25T02:28:31.613433Z","iopub.status.idle":"2022-04-25T02:28:39.044206Z","shell.execute_reply.started":"2022-04-25T02:28:31.613390Z","shell.execute_reply":"2022-04-25T02:28:39.043427Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### **Sales Product-Families in 2017**","metadata":{}},{"cell_type":"code","source":"top_family = df_train.loc[df_train['date'].dt.year==2017].groupby(['family']).agg({'sales':'sum'}).sort_values(by=\"sales\", ascending=True)\nfigsize = (13,13)\nfig, ax1 = plt.subplots(figsize=figsize)\ntop_family.plot(kind=\"barh\",ax=ax1)\nax1.set(title=\"Top Product Families in 2017 (in Log scale)\")\nax1.set(ylabel=\"Product Family\", xlabel=\"Average Sales (in Log scale)\", xscale=\"log\")\nax1.get_legend().remove()\n\nfor item in ([ax1.xaxis.label, ax1.yaxis.label]+ax1.get_xticklabels() + ax1.get_yticklabels()):\n    item.set_fontsize(\"large\")\nax1.title.set_fontsize(\"xx-large\")    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:39.045336Z","iopub.execute_input":"2022-04-25T02:28:39.045745Z","iopub.status.idle":"2022-04-25T02:28:40.286901Z","shell.execute_reply.started":"2022-04-25T02:28:39.045715Z","shell.execute_reply":"2022-04-25T02:28:40.286074Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### **Sales by Cluster in 2017**","metadata":{}},{"cell_type":"code","source":"top_stores_2017 = df_train.loc[df_train.date.dt.year==2017].groupby(\"store_nbr\").agg({\"sales\":\"sum\"})\ntop_stores_2017 = pd.merge(top_stores_2017, df_stores, on=\"store_nbr\").drop([\"city\",\"state\"],axis=1)\n\nfigsize = (15,5)\nfig, (ax1,ax2) = plt.subplots(1,2,figsize=figsize)\ntop_stores_2017.groupby(['type']).agg({'sales':'mean'}).plot.pie(y=\"sales\",ax=ax1, legend=False, autopct='%1.f%%',\n                             startangle=90, labels=[\"Type A\",\"Type B\",\"Type C\",\"Type D\",\"Type E\"], fontsize=\"x-large\")\nax1.set(title=\"Average Sales by Type\")\n\ntop_stores_2017.groupby(['cluster']).agg({'sales':'mean'}).plot.bar(ax=ax2,  fontsize=\"large\")\nax2.set(title=\"Average Sales by Cluster\")\nax2.set(ylabel=\"Average Sales\", xlabel=\"Cluster\")\nax2.get_legend().remove()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:40.288036Z","iopub.execute_input":"2022-04-25T02:28:40.288275Z","iopub.status.idle":"2022-04-25T02:28:40.967275Z","shell.execute_reply.started":"2022-04-25T02:28:40.288248Z","shell.execute_reply":"2022-04-25T02:28:40.966670Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion: Top Sales by Type and Cluster in 2017**\n\n* Store Type A has the highest sales which is 37%, followed by Types B and D.\n* Store Cluster 5 has the highest sales, followed by Clusters 11, 14, and 8.\n\n","metadata":{}},{"cell_type":"markdown","source":"## **Transaction Analysis : Seasonality and Trend**\n\nWe would like to know how the sales behave at different times to understand their seasonality and the overall trend. Seasonalities include each season, monthly, quarterly.","metadata":{}},{"cell_type":"code","source":"figsize = (14,4)\nfig, ax = plt.subplots(figsize=figsize)\nsales_grouped. plot(ax=ax, alpha=0.3)\nsales_smooth7. plot(ax=ax)\nsales_smooth365.plot(ax=ax, color=\"r\")\nax.legend([\"Daily Sales\",\"7-day Moving Average\",\"365-day Moving Average\"],bbox_to_anchor=(1.0, 1.0))\nax.set(ylim=2e5, title=\"Sales per Day for all Stores\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:40.968589Z","iopub.execute_input":"2022-04-25T02:28:40.969031Z","iopub.status.idle":"2022-04-25T02:28:41.858462Z","shell.execute_reply.started":"2022-04-25T02:28:40.968999Z","shell.execute_reply":"2022-04-25T02:28:41.857897Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"figsize = (16,5)\nfig, (ax1,ax2) = plt.subplots(1,2,figsize=figsize)\nsales_grouped. plot(ax=ax1)\nsales_smooth7. plot(ax=ax1, color=\"r\")\nax1.legend([\"Daily sales\",\"7-Day Moving Average Sales\"])\nax1.set(ylim=[2e5, 8e5], title=\"2013 Sales per Day for all Stores\")\nax1.set(xlim=[sales_grouped.index[0],sales_grouped.index[365]] )\n##############\nsales_grouped. plot(ax=ax2)\nsales_smooth7. plot(ax=ax2, color=\"r\")\nax2.legend([\"Daily Sales\",\"7-Day Moving Average Sales\"])\nax2.set(ylim=4e5, title=\"2016-2017 Sales per Day for all Stores\")\nax2.set(xlim=[sales_grouped.index[-365],sales_grouped.index[-1]] )\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:41.859757Z","iopub.execute_input":"2022-04-25T02:28:41.860128Z","iopub.status.idle":"2022-04-25T02:28:43.338901Z","shell.execute_reply.started":"2022-04-25T02:28:41.860097Z","shell.execute_reply":"2022-04-25T02:28:43.338312Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion: Sales in period of 365 days**\n\nBased on zoomed-in graphs, we could see 12 peaks of sales for 365 days (equivalently 12 months or a year). Hence, there is a monthly frequency. Moreover, the sales increased dramatically during the transition times from the preview year to the new year which presented an annual pattern. (The sales were smoothed with 7-day MA to eliminate the weekly pattern)\n\n","metadata":{}},{"cell_type":"markdown","source":"## **Split X & y**","metadata":{}},{"cell_type":"code","source":"y=df_train1['sales']\nX = df_train1.drop('sales',axis=1)\nX","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:43.340192Z","iopub.execute_input":"2022-04-25T02:28:43.340617Z","iopub.status.idle":"2022-04-25T02:28:45.885467Z","shell.execute_reply.started":"2022-04-25T02:28:43.340579Z","shell.execute_reply":"2022-04-25T02:28:45.884687Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(data = df_train1, index = \"year\", columns = \"month\", values = \"sales\", aggfunc=\"sum\")","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:45.886649Z","iopub.execute_input":"2022-04-25T02:28:45.886865Z","iopub.status.idle":"2022-04-25T02:28:46.108698Z","shell.execute_reply.started":"2022-04-25T02:28:45.886840Z","shell.execute_reply":"2022-04-25T02:28:46.107923Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## **Train-Test Split**\nWe divide the data such that TRAIN set contains Year upto 2016 and TEST set contains Year from 2016","metadata":{}},{"cell_type":"code","source":"sp = len(X[X.year <= 2016])\n\nX_train = X[:sp]\nX_test = X[sp:]\n\ny_train = y[:sp]\ny_test = y[sp:]\n\n# X_train\nX_test\n# y_train\n# y_test","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:46.109875Z","iopub.execute_input":"2022-04-25T02:28:46.110129Z","iopub.status.idle":"2022-04-25T02:28:46.866656Z","shell.execute_reply.started":"2022-04-25T02:28:46.110101Z","shell.execute_reply":"2022-04-25T02:28:46.865724Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## **FB-Prophet**\n\nProphet follows the sklearn model API. We create an instance of the Prophet class and then call its fit and predict methods.\n\nThe input to Prophet is always a dataframe with two columns: ds and y. The ds (datestamp) column should be of a format expected by Pandas, ideally YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp. The y column must be numeric, and represents the measurement we wish to forecast.\n\n**Prophet DOES NOT require any Feature Engineering**","metadata":{}},{"cell_type":"code","source":"data={'ds':df_train1['date'],\n     'y':y_train}\n\ndf=pd.DataFrame(data)\n\ndf","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:46.870748Z","iopub.execute_input":"2022-04-25T02:28:46.871470Z","iopub.status.idle":"2022-04-25T02:28:47.145419Z","shell.execute_reply.started":"2022-04-25T02:28:46.871419Z","shell.execute_reply":"2022-04-25T02:28:47.144505Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"! pip install prophet","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:28:47.146708Z","iopub.execute_input":"2022-04-25T02:28:47.147014Z","iopub.status.idle":"2022-04-25T02:30:21.953488Z","shell.execute_reply.started":"2022-04-25T02:28:47.146973Z","shell.execute_reply":"2022-04-25T02:30:21.952744Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from prophet import Prophet\n\nm = Prophet()\n\nm.fit(df)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:30:21.954984Z","iopub.execute_input":"2022-04-25T02:30:21.955343Z","iopub.status.idle":"2022-04-25T02:56:09.682352Z","shell.execute_reply.started":"2022-04-25T02:30:21.955294Z","shell.execute_reply":"2022-04-25T02:56:09.681542Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## **Predicting**","metadata":{}},{"cell_type":"code","source":"df=pd.DataFrame({'ds': X_test['date']})\npred = m.predict(df)","metadata":{"execution":{"iopub.status.busy":"2022-04-25T02:56:09.683582Z","iopub.execute_input":"2022-04-25T02:56:09.683833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Plot train, test, forecast\nfig = m.plot(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Scoring**","metadata":{}},{"cell_type":"code","source":"# # Calculate RMSE and MAPE\nrsme = np.sqrt(np.sum((y_test-pred)**2)/len(y_test))\n# # mape = (100/len(y_test)) * np.sum(np.abs((y_test-pred)/y_test))\n\n# print('RSME :',rsme)\n# # print('MAPE :',mape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dff = pd.DataFrame({'ds':df_test1['dates']})\n\nsubmission=pd.DataFrame({'id': df_test1.id,\n                         'sales' :m.predict(dff)\n                        })\nsubmission.head(20)\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Suggestions:-**\n* Kaggle - https://www.kaggle.com/pythonkumar\n* GitHub - https://github.com/KumarPython​\n* Twitter - https://twitter.com/KumarPython\n* LinkedIn - https://www.linkedin.com/in/kumarpython/ ","metadata":{}}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-01T09:59:25.293240Z","iopub.execute_input":"2022-05-01T09:59:25.293653Z","iopub.status.idle":"2022-05-01T09:59:25.333326Z","shell.execute_reply.started":"2022-05-01T09:59:25.293533Z","shell.execute_reply":"2022-05-01T09:59:25.332642Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:25.337598Z","iopub.execute_input":"2022-05-01T09:59:25.339493Z","iopub.status.idle":"2022-05-01T09:59:28.552012Z","shell.execute_reply.started":"2022-05-01T09:59:25.339455Z","shell.execute_reply":"2022-05-01T09:59:28.551183Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\nid=test['Id']\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:28.553575Z","iopub.execute_input":"2022-05-01T09:59:28.553838Z","iopub.status.idle":"2022-05-01T09:59:28.653805Z","shell.execute_reply.started":"2022-05-01T09:59:28.553802Z","shell.execute_reply":"2022-05-01T09:59:28.653044Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Information","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:28.655144Z","iopub.execute_input":"2022-05-01T09:59:28.656237Z","iopub.status.idle":"2022-05-01T09:59:28.687994Z","shell.execute_reply.started":"2022-05-01T09:59:28.656190Z","shell.execute_reply":"2022-05-01T09:59:28.687010Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Unique Values","metadata":{}},{"cell_type":"code","source":"train.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:28.691219Z","iopub.execute_input":"2022-05-01T09:59:28.691544Z","iopub.status.idle":"2022-05-01T09:59:28.718351Z","shell.execute_reply.started":"2022-05-01T09:59:28.691503Z","shell.execute_reply":"2022-05-01T09:59:28.717333Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Columns with Null Values","metadata":{}},{"cell_type":"code","source":"null_train=train.columns[train.isnull().any()]\nnull_train","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:28.720297Z","iopub.execute_input":"2022-05-01T09:59:28.720628Z","iopub.status.idle":"2022-05-01T09:59:28.736930Z","shell.execute_reply.started":"2022-05-01T09:59:28.720574Z","shell.execute_reply":"2022-05-01T09:59:28.735859Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"null_test=test.columns[test.isnull().any()]\nnull_test","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:28.738365Z","iopub.execute_input":"2022-05-01T09:59:28.739055Z","iopub.status.idle":"2022-05-01T09:59:28.754812Z","shell.execute_reply.started":"2022-05-01T09:59:28.739015Z","shell.execute_reply":"2022-05-01T09:59:28.753980Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Histogram","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nfig = px.histogram(train, x='SalePrice',color='Street',marginal=\"box\") # Whether Price depends upon Street\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:28.756155Z","iopub.execute_input":"2022-05-01T09:59:28.756445Z","iopub.status.idle":"2022-05-01T09:59:29.741557Z","shell.execute_reply.started":"2022-05-01T09:59:28.756405Z","shell.execute_reply":"2022-05-01T09:59:29.740906Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.histogram(train, x='SalePrice',color='LotShape',marginal=\"rug\") # Whether PRICE Depends upon LotShape\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:29.742746Z","iopub.execute_input":"2022-05-01T09:59:29.743219Z","iopub.status.idle":"2022-05-01T09:59:29.856947Z","shell.execute_reply.started":"2022-05-01T09:59:29.743181Z","shell.execute_reply":"2022-05-01T09:59:29.856129Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.histogram(train, x='SalePrice',color='LotConfig',marginal=\"rug\") # Whether PRICE Depends upon LotConfig\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:29.858315Z","iopub.execute_input":"2022-05-01T09:59:29.858656Z","iopub.status.idle":"2022-05-01T09:59:29.969355Z","shell.execute_reply.started":"2022-05-01T09:59:29.858619Z","shell.execute_reply":"2022-05-01T09:59:29.968708Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.histogram(train, x='SalePrice',color='Neighborhood',marginal=\"rug\") # Whether PRICE Depends upon Neighborhood\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:29.970419Z","iopub.execute_input":"2022-05-01T09:59:29.970798Z","iopub.status.idle":"2022-05-01T09:59:30.266416Z","shell.execute_reply.started":"2022-05-01T09:59:29.970763Z","shell.execute_reply":"2022-05-01T09:59:30.265679Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.histogram(train, x='SalePrice',color='Condition1',marginal=\"rug\") # Whether PRICE Depends upon Condition1\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:30.267774Z","iopub.execute_input":"2022-05-01T09:59:30.268220Z","iopub.status.idle":"2022-05-01T09:59:30.418537Z","shell.execute_reply.started":"2022-05-01T09:59:30.268179Z","shell.execute_reply":"2022-05-01T09:59:30.417780Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.histogram(train, x='SalePrice',color='BldgType',marginal=\"rug\") # Whether PRICE Depends upon BldgType\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:30.419950Z","iopub.execute_input":"2022-05-01T09:59:30.420382Z","iopub.status.idle":"2022-05-01T09:59:30.541248Z","shell.execute_reply.started":"2022-05-01T09:59:30.420342Z","shell.execute_reply":"2022-05-01T09:59:30.540497Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.histogram(train, x='SalePrice',color='HouseStyle',marginal=\"rug\") # Whether PRICE Depends upon HouseStyle\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:30.545270Z","iopub.execute_input":"2022-05-01T09:59:30.545690Z","iopub.status.idle":"2022-05-01T09:59:30.690420Z","shell.execute_reply.started":"2022-05-01T09:59:30.545650Z","shell.execute_reply":"2022-05-01T09:59:30.689605Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Boxplot","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nfig = px.box(train, y=\"SalePrice\",points=\"all\",color=\"RoofMatl\")   # Boxplot based on SalePrice for RoofMatl\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:30.691785Z","iopub.execute_input":"2022-05-01T09:59:30.692188Z","iopub.status.idle":"2022-05-01T09:59:30.779133Z","shell.execute_reply.started":"2022-05-01T09:59:30.692151Z","shell.execute_reply":"2022-05-01T09:59:30.778442Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.box(train, y=\"SalePrice\",points=\"all\",color=\"HouseStyle\")   # Boxplot based on SalePrice for HouseStyle\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:30.780409Z","iopub.execute_input":"2022-05-01T09:59:30.780783Z","iopub.status.idle":"2022-05-01T09:59:30.859413Z","shell.execute_reply.started":"2022-05-01T09:59:30.780745Z","shell.execute_reply":"2022-05-01T09:59:30.858549Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.box(train, y=\"SalePrice\",points=\"all\",color=\"SaleCondition\")   # Boxplot based on SalePrice for SaleCondition\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:30.860915Z","iopub.execute_input":"2022-05-01T09:59:30.861200Z","iopub.status.idle":"2022-05-01T09:59:30.936381Z","shell.execute_reply.started":"2022-05-01T09:59:30.861165Z","shell.execute_reply":"2022-05-01T09:59:30.935712Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.box(train, y=\"SalePrice\",points=\"all\",color=\"YrSold\")   # Boxplot based on SalePrice for YrSold\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:30.937544Z","iopub.execute_input":"2022-05-01T09:59:30.937920Z","iopub.status.idle":"2022-05-01T09:59:31.006039Z","shell.execute_reply.started":"2022-05-01T09:59:30.937882Z","shell.execute_reply":"2022-05-01T09:59:31.005405Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.box(train, y=\"SalePrice\",points=\"all\",color=\"PoolArea\")   # Boxplot based on SalePrice for PoolArea\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:31.007240Z","iopub.execute_input":"2022-05-01T09:59:31.007614Z","iopub.status.idle":"2022-05-01T09:59:31.084475Z","shell.execute_reply.started":"2022-05-01T09:59:31.007565Z","shell.execute_reply":"2022-05-01T09:59:31.083829Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.box(train, y=\"SalePrice\",points=\"all\",color=\"GarageArea\")   # Boxplot based on SalePrice for GarageArea\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:31.085668Z","iopub.execute_input":"2022-05-01T09:59:31.086019Z","iopub.status.idle":"2022-05-01T09:59:32.396552Z","shell.execute_reply.started":"2022-05-01T09:59:31.085981Z","shell.execute_reply":"2022-05-01T09:59:32.395572Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.box(train, y=\"SalePrice\",points=\"all\",color=\"Fireplaces\")   # Boxplot based on SalePrice for Fireplaces\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:32.397616Z","iopub.execute_input":"2022-05-01T09:59:32.397849Z","iopub.status.idle":"2022-05-01T09:59:32.476256Z","shell.execute_reply.started":"2022-05-01T09:59:32.397818Z","shell.execute_reply":"2022-05-01T09:59:32.475387Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Jointplot","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nfig = px.scatter(train,x='SalePrice',y='BedroomAbvGr',color='BedroomAbvGr',marginal_y=\"histogram\",marginal_x=\"histogram\")   # Jointplot whether SalePrice depends upon  BedroomAbvGr\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:32.477822Z","iopub.execute_input":"2022-05-01T09:59:32.478092Z","iopub.status.idle":"2022-05-01T09:59:32.647645Z","shell.execute_reply.started":"2022-05-01T09:59:32.478045Z","shell.execute_reply":"2022-05-01T09:59:32.646908Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.scatter(train, x='SalePrice', y='KitchenAbvGr',color='KitchenAbvGr', marginal_y=\"histogram\", marginal_x=\"histogram\")   # Jointplot whether SalePrice depends upon  KitchenAbvGr\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:32.649145Z","iopub.execute_input":"2022-05-01T09:59:32.649679Z","iopub.status.idle":"2022-05-01T09:59:32.780744Z","shell.execute_reply.started":"2022-05-01T09:59:32.649621Z","shell.execute_reply":"2022-05-01T09:59:32.780011Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.scatter(train, x='SalePrice', y='FullBath',color='FullBath', marginal_y=\"histogram\", marginal_x=\"histogram\")   # Jointplot whether SalePrice depends upon  FullBath\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:32.782165Z","iopub.execute_input":"2022-05-01T09:59:32.782587Z","iopub.status.idle":"2022-05-01T09:59:32.926564Z","shell.execute_reply.started":"2022-05-01T09:59:32.782547Z","shell.execute_reply":"2022-05-01T09:59:32.925544Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.scatter(train, x='SalePrice', y='BsmtFullBath',color='BsmtFullBath',marginal_y=\"histogram\", marginal_x=\"histogram\")   # Jointplot whether SalePrice depends upon  BsmtFullBath\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:32.928303Z","iopub.execute_input":"2022-05-01T09:59:32.928624Z","iopub.status.idle":"2022-05-01T09:59:33.052650Z","shell.execute_reply.started":"2022-05-01T09:59:32.928572Z","shell.execute_reply":"2022-05-01T09:59:33.051788Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.scatter(train, x='SalePrice', y='TotRmsAbvGrd',color='TotRmsAbvGrd',marginal_y=\"histogram\", marginal_x=\"histogram\")   # Jointplot whether SalePrice depends upon  TotRmsAbvGrd\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:33.053918Z","iopub.execute_input":"2022-05-01T09:59:33.054260Z","iopub.status.idle":"2022-05-01T09:59:33.174413Z","shell.execute_reply.started":"2022-05-01T09:59:33.054223Z","shell.execute_reply":"2022-05-01T09:59:33.173763Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.scatter(train, x='SalePrice', y='GrLivArea',color='GrLivArea',marginal_y=\"histogram\", marginal_x=\"histogram\")   # Jointplot whether SalePrice depends upon  GrLivArea\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:33.175607Z","iopub.execute_input":"2022-05-01T09:59:33.175950Z","iopub.status.idle":"2022-05-01T09:59:33.294790Z","shell.execute_reply.started":"2022-05-01T09:59:33.175916Z","shell.execute_reply":"2022-05-01T09:59:33.294135Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## 2D Histogram","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nfig = px.density_heatmap(train, x=\"SalePrice\", y=\"1stFlrSF\", marginal_x=\"histogram\", marginal_y=\"histogram\")   # 2D Histogram for SalePrice against 1stFlrSF\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:33.296035Z","iopub.execute_input":"2022-05-01T09:59:33.296434Z","iopub.status.idle":"2022-05-01T09:59:33.419450Z","shell.execute_reply.started":"2022-05-01T09:59:33.296398Z","shell.execute_reply":"2022-05-01T09:59:33.418795Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.density_heatmap(train, x=\"SalePrice\", y=\"2ndFlrSF\",marginal_x=\"histogram\", marginal_y=\"histogram\")   # 2D Histogram for SalePrice against 2ndFlrSF\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:33.420595Z","iopub.execute_input":"2022-05-01T09:59:33.421363Z","iopub.status.idle":"2022-05-01T09:59:33.536805Z","shell.execute_reply.started":"2022-05-01T09:59:33.421322Z","shell.execute_reply":"2022-05-01T09:59:33.535943Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.density_heatmap(train, x=\"SalePrice\", y=\"CentralAir\",marginal_x=\"histogram\", marginal_y=\"histogram\")   # 2D Histogram for SalePrice against CentralAir\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:33.538110Z","iopub.execute_input":"2022-05-01T09:59:33.538998Z","iopub.status.idle":"2022-05-01T09:59:33.666119Z","shell.execute_reply.started":"2022-05-01T09:59:33.538955Z","shell.execute_reply":"2022-05-01T09:59:33.665507Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.density_heatmap(train, x=\"SalePrice\", y=\"Heating\",marginal_x=\"histogram\", marginal_y=\"histogram\")   # 2D Histogram for SalePrice against Heating\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:33.667113Z","iopub.execute_input":"2022-05-01T09:59:33.667459Z","iopub.status.idle":"2022-05-01T09:59:33.793322Z","shell.execute_reply.started":"2022-05-01T09:59:33.667426Z","shell.execute_reply":"2022-05-01T09:59:33.792515Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.density_heatmap(train, x=\"SalePrice\", y=\"Foundation\",marginal_x=\"histogram\", marginal_y=\"histogram\")   # 2D Histogram for SalePrice against Foundation\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:33.794777Z","iopub.execute_input":"2022-05-01T09:59:33.795027Z","iopub.status.idle":"2022-05-01T09:59:33.921394Z","shell.execute_reply.started":"2022-05-01T09:59:33.794992Z","shell.execute_reply":"2022-05-01T09:59:33.920673Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Heatmap","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nfig = px.imshow(train.corr(), text_auto=True,aspect=\"auto\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:33.922480Z","iopub.execute_input":"2022-05-01T09:59:33.922835Z","iopub.status.idle":"2022-05-01T09:59:33.980811Z","shell.execute_reply.started":"2022-05-01T09:59:33.922803Z","shell.execute_reply":"2022-05-01T09:59:33.980032Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Drop some Columns","metadata":{}},{"cell_type":"code","source":"train=train.drop(columns=['SalePrice','Id'], axis=1)\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:33.982161Z","iopub.execute_input":"2022-05-01T09:59:33.982863Z","iopub.status.idle":"2022-05-01T09:59:34.015291Z","shell.execute_reply.started":"2022-05-01T09:59:33.982824Z","shell.execute_reply":"2022-05-01T09:59:34.014646Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"test=test.drop(columns=['Id'], axis=1)\ntest","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:34.016522Z","iopub.execute_input":"2022-05-01T09:59:34.016939Z","iopub.status.idle":"2022-05-01T09:59:34.047894Z","shell.execute_reply.started":"2022-05-01T09:59:34.016900Z","shell.execute_reply":"2022-05-01T09:59:34.047136Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## Seperate Cols w.r.t Datatypes","metadata":{}},{"cell_type":"code","source":"num_train = train.select_dtypes(include=['int64','float64','UInt32'])\ncat_train = train.select_dtypes(include=['object','string'])\nnum_train\n# cat_train","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:34.049305Z","iopub.execute_input":"2022-05-01T09:59:34.049557Z","iopub.status.idle":"2022-05-01T09:59:34.078850Z","shell.execute_reply.started":"2022-05-01T09:59:34.049523Z","shell.execute_reply":"2022-05-01T09:59:34.078248Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"num_test = test.select_dtypes(include=['int64','float64','UInt32'])\ncat_test = test.select_dtypes(include=['object','string'])\n# num_test\ncat_test","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:34.080194Z","iopub.execute_input":"2022-05-01T09:59:34.080454Z","iopub.status.idle":"2022-05-01T09:59:34.111536Z","shell.execute_reply.started":"2022-05-01T09:59:34.080419Z","shell.execute_reply":"2022-05-01T09:59:34.110695Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## Encoding\n\nTypically any standard workflow in feature engineering involves some form of transformation of these categorical values into numeric labels and then applying some encoding scheme on these values.\n\n* Nominal attributes consist of discrete categorical values with no notion or sense of order amongst them.\n* Ordinal attributes are categorical attributes with a sense of order amongst the values.","metadata":{}},{"cell_type":"code","source":"# Label Encoding - This transformer should be used to encode 1 COLUMN at a Time\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\nfor cat in cat_train:\n    train[cat]=le.fit_transform(train[cat])\n    \ntrain","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:34.112711Z","iopub.execute_input":"2022-05-01T09:59:34.113014Z","iopub.status.idle":"2022-05-01T09:59:34.172983Z","shell.execute_reply.started":"2022-05-01T09:59:34.112978Z","shell.execute_reply":"2022-05-01T09:59:34.172135Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"for cat in cat_test:\n    test[cat]=le.fit_transform(test[cat])\ntest","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:34.174498Z","iopub.execute_input":"2022-05-01T09:59:34.174745Z","iopub.status.idle":"2022-05-01T09:59:34.232323Z","shell.execute_reply.started":"2022-05-01T09:59:34.174711Z","shell.execute_reply":"2022-05-01T09:59:34.231555Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## Impute\n\nMissing values are one of the most common problems you can encounter when you try to prepare your data for machine learning. The reason for the missing values might be human errors,interruptions in the data flow, privacy concerns, and so on. Whatever is the reason, missing values affect the performance of the machine learning models.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nimp = SimpleImputer(strategy='most_frequent')\n\ntrain[null_train] = imp.fit_transform(train[null_train])\ntrain.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:34.233669Z","iopub.execute_input":"2022-05-01T09:59:34.233992Z","iopub.status.idle":"2022-05-01T09:59:34.260440Z","shell.execute_reply.started":"2022-05-01T09:59:34.233955Z","shell.execute_reply":"2022-05-01T09:59:34.259616Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"test[null_test] = imp.fit_transform(test[null_test])\ntest.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:34.265343Z","iopub.execute_input":"2022-05-01T09:59:34.265528Z","iopub.status.idle":"2022-05-01T09:59:34.292527Z","shell.execute_reply.started":"2022-05-01T09:59:34.265505Z","shell.execute_reply":"2022-05-01T09:59:34.291747Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"## Removing Outliers\n\nIn statistics, an outlier is a data point that differs significantly from other observations. An outlier may be due to variability in the measurement or it may indicate experimental error; the latter are sometimes excluded from the data set. An outlier can cause serious problems in statistical analyses.","metadata":{}},{"cell_type":"code","source":"# Using Isolation Forest\nfrom sklearn.ensemble import IsolationForest\niso = IsolationForest(contamination=0.3)\n\nout = iso.fit_predict(train)\n\n# select all rows that are not outliers\ntrain[out != -1]\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:34.293899Z","iopub.execute_input":"2022-05-01T09:59:34.294168Z","iopub.status.idle":"2022-05-01T09:59:34.739622Z","shell.execute_reply.started":"2022-05-01T09:59:34.294135Z","shell.execute_reply":"2022-05-01T09:59:34.738650Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"out = iso.fit_predict(test)\n\n# select all rows that are not outliers\ntest[out != -1]\ntest","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:34.741003Z","iopub.execute_input":"2022-05-01T09:59:34.741367Z","iopub.status.idle":"2022-05-01T09:59:35.192441Z","shell.execute_reply.started":"2022-05-01T09:59:34.741327Z","shell.execute_reply":"2022-05-01T09:59:35.191620Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## Seperate Cols having\n* Continuous values\n* Discreet values","metadata":{}},{"cell_type":"code","source":"con_train =[col for col in num_train if train[col].nunique()>100]\ndis_train =[col for col in num_train if train[col].nunique()<100]\ncon_train\n# dis_trsin","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:35.193875Z","iopub.execute_input":"2022-05-01T09:59:35.194151Z","iopub.status.idle":"2022-05-01T09:59:35.210366Z","shell.execute_reply.started":"2022-05-01T09:59:35.194117Z","shell.execute_reply":"2022-05-01T09:59:35.209554Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"con_test =[col for col in num_test if test[col].nunique()>25]\ndis_test =[col for col in num_test if test[col].nunique()<25]\n# con_test\ndis_test","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:35.211772Z","iopub.execute_input":"2022-05-01T09:59:35.212093Z","iopub.status.idle":"2022-05-01T09:59:35.229298Z","shell.execute_reply.started":"2022-05-01T09:59:35.212042Z","shell.execute_reply":"2022-05-01T09:59:35.228527Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"## Standardizing - Discrete Values\n\nStandardization (or z-score normalization) scales the values while taking into account standard deviation. If the standard deviation of features is different, their range also would differ from each other. This reduces the effect of the outliers in the features.","metadata":{}},{"cell_type":"code","source":"# RobustScaler\nfrom sklearn.preprocessing import RobustScaler\n\nrs = RobustScaler()\n\ntrain[dis_train]= rs.fit_transform(train[dis_train])\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:35.230473Z","iopub.execute_input":"2022-05-01T09:59:35.230798Z","iopub.status.idle":"2022-05-01T09:59:35.275971Z","shell.execute_reply.started":"2022-05-01T09:59:35.230758Z","shell.execute_reply":"2022-05-01T09:59:35.275202Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"test[dis_test]= rs.fit_transform(test[dis_test])\ntest","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:35.277679Z","iopub.execute_input":"2022-05-01T09:59:35.277923Z","iopub.status.idle":"2022-05-01T09:59:35.323134Z","shell.execute_reply.started":"2022-05-01T09:59:35.277891Z","shell.execute_reply":"2022-05-01T09:59:35.322365Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"## Log Transformation - Continuous Data\n\nLog transform helps in handling the skewed data, and it makes the distribution more approximate to normal after transformation. It also reduces the effects of outliers on the data, as because of the normalization of magnitude differences, a model becomes much robust.","metadata":{}},{"cell_type":"code","source":"train[con_train]=np.log1p(train[con_train])\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:35.324456Z","iopub.execute_input":"2022-05-01T09:59:35.324700Z","iopub.status.idle":"2022-05-01T09:59:35.362185Z","shell.execute_reply.started":"2022-05-01T09:59:35.324668Z","shell.execute_reply":"2022-05-01T09:59:35.361365Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"test[con_test]=np.log1p(test[con_test])\ntest","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:35.363445Z","iopub.execute_input":"2022-05-01T09:59:35.363786Z","iopub.status.idle":"2022-05-01T09:59:35.405909Z","shell.execute_reply.started":"2022-05-01T09:59:35.363747Z","shell.execute_reply":"2022-05-01T09:59:35.405039Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"## Splitting X & y","metadata":{}},{"cell_type":"code","source":"train1=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ny=train1['SalePrice']\nX=train\ny\n# X","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:35.407466Z","iopub.execute_input":"2022-05-01T09:59:35.407712Z","iopub.status.idle":"2022-05-01T09:59:35.437811Z","shell.execute_reply.started":"2022-05-01T09:59:35.407679Z","shell.execute_reply":"2022-05-01T09:59:35.437115Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"## Train Test Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n# X_train\n# X_test\ny_train\n# y_test","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:35.438826Z","iopub.execute_input":"2022-05-01T09:59:35.439083Z","iopub.status.idle":"2022-05-01T09:59:35.453205Z","shell.execute_reply.started":"2022-05-01T09:59:35.439030Z","shell.execute_reply":"2022-05-01T09:59:35.452567Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost hyperparameters \n\n**XGBoost Hyperparameters have been divided into 4 categories.** They are as follows -\n\n1. General parameters\n2. Booster parameters\n3. Learning task parameters\n4. Command line parameters\n\n\n## **1-General Parameters**\n\nThese parameters guide the overall functioning of the XGBoost model.\n\nIn this section, we will discuss three hyperparameters - booster, verbosity and nthread.\n\n**1.1 booster (default =gbtree)**\n\nbooster parameter helps us to choose which booster to use.\nIt helps us to select the type of model to run at each iteration.\nIt has 3 options - gbtree, gblinear or dart.\n\ngbtree and dart - use tree-based models, while\ngblinear uses linear models.\n\n**1.2 verbosity**\n\nVerbosity of printing messages.\nValid values are 0 (silent), 1 (warning), 2 (info), 3 (debug).\n\n**1.3 nthread(default = maximum number of threads available if not set)**\n\nThis is number of parallel threads used to run XGBoost.This is used for parallel processing and number of cores in the system should be entered.If you wish to run on all cores, value should not be entered and algorithm will detect automatically.\n\n## **2-Booster Parameters**\n\nWe have 2 types of boosters - tree booster and linear booster.\nWe will limit our discussion to tree booster because it always outperforms the linear booster and thus the later is rarely used.\n\n**2.1 eta(default=0.3, alias: learning_rate)**\n\n* It is analogous to learning rate in GBM.\n* It is the step size shrinkage used in update to prevent overfitting.\n* After each boosting step, we can directly get the weights of new features, and eta shrinks the feature weights to make the boosting process more conservative.\n* It makes the model more robust by shrinking the weights on each step.\n\n**2.2 gamma(default=0, alias: min_split_loss)**\n\n* A node is split only when the resulting split gives a positive reduction in the loss function.\n* Gamma specifies the minimum loss reduction required to make a split.\n* It makes the algorithm conservative. The values can vary depending on the loss function and should be tuned.\n* The larger gamma is, the more conservative the algorithm will be.\n\n**2.3 max_depth(default=6)\n\n* The maximum depth of a tree, same as GBM.\n* It is used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.\n* Increasing this value will make the model more complex and more likely to overfit.\n* The value 0 is only accepted in lossguided growing policy when tree_method is set as hist and it indicates no limit on depth.\n* We should be careful when setting large value of max_depth because XGBoost aggressively consumes memory when training a deep tree.\n\n**2.4 min_child_weight(default=1)**\n\n* It defines the minimum sum of weights of all observations required in a child.\n* This is similar to min_child_leaf in GBM but not exactly. This refers to min “sum of weights” of observations while GBM has min “number of observations”.\n* It is used to control over-fitting.\n* Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n* Too high values can lead to under-fitting.Hence, it should be tuned using CV.The larger min_child_weight is, the more conservative the algorithm will be.\n\n**2.5 max_delta_step(default=0)\n\n* In maximum delta step we allow each tree’s weight estimation to be.\n* If the value is set to 0, it means there is no constraint.\n* If it is set to a positive value, it can help making the update step more conservative.\n* Usually this parameter is not needed, but it might help in logistic regression when class is extremely imbalanced.\n\n**subsample(default=1)**\n\n* It denotes the fraction of observations to be randomly samples for each tree.\n* Subsample ratio of the training instances.\n* Setting it to 0.5 means that XGBoost would randomly sample half of the training data prior to growing trees. - This will prevent overfitting.\n* Subsampling will occur once in every boosting iteration.\n* Lower values make the algorithm more conservative and prevents overfitting but too small values might lead to under-fitting.\nTypical values: 0.5-1\n\n**2.7 colsample_bytree, colsample_bylevel, colsample_bynode**\n\n* colsample_bytree, colsample_bylevel, colsample_bynode [default=1]\nAll colsample_by parameters have a range of (0, 1], the default value of 1, and specify the fraction of columns to be subsampled.\n\n* colsample_bytree is the subsample ratio of columns when constructing each tree. Subsampling occurs once for every tree constructed.\ncolsample_bylevel is the subsample ratio of columns for each level. Subsampling occurs once for every new depth level reached in a tree. Columns are subsampled from the set of columns chosen for the current tree.\n\n* colsample_bynode is the subsample ratio of columns for each node (split). Subsampling occurs once every time a new split is evaluated. Columns are subsampled from the set of columns chosen for the current level.\n\n* colsample_by* parameters work cumulatively. For instance, the combination {'colsample_bytree':0.5, 'colsample_bylevel':0.5, 'colsample_bynode':0.5} with 64 features will leave 8 features to choose from at each split.\n\n**2.8 lambda(default=1, alias: reg_lambda)**\n\n* L2 regularization term on weights (analogous to Ridge regression).\n* This is used to handle the regularization part of XGBoost.\n* Increasing this value will make model more conservative.\n\n**2.9 alpha(default=0, alias: reg_alpha)**\n\n* L1 regularization term on weights (analogous to Lasso regression).\n* It can be used in case of very high dimensionality so that the algorithm runs faster when implemented.\n* Increasing this value will make model more conservative.\n\n**2.10 tree_method string(default= auto)**\n\n* XGBoost supports approx, hist and gpu_hist for distributed training. Experimental support for external memory is available for approx and gpu_hist.\n* Choices: auto, exact, approx, hist, gpu_hist\n* auto: Use heuristic to choose the fastest method.\n* For small to medium dataset, exact greedy (exact) will be used.\n* For very large dataset, approximate algorithm (approx) will be chosen.\n* Because old behavior is always use exact greedy in single machine, user will get a message when approximate algorithm is chosen to notify this choice.\n* exact: Exact greedy algorithm.\n* approx: Approximate greedy algorithm using quantile sketch and gradient histogram.\n* hist: Fast histogram optimized approximate greedy algorithm. It uses some performance improvements such as bins caching.\n* gpu_hist: GPU implementation of hist algorithm.\n\n**2.11 scale_pos_weight(default=1)**\n\n* It controls the balance of positive and negative weights,\n* It is useful for imbalanced classes.\n* A value greater than 0 should be used in case of high class imbalance as it helps in faster convergence.\n* A typical value to consider: sum(negative instances) / sum(positive instances).\n\n## 3-Learning Task Parameters \n\nThese parameters are used to define the optimization objective the metric to be calculated at each step.\nThey are used to specify the learning task and the corresponding learning objective. The objective options are below:\n\n**3.1 objective(default=reg:squarederror)**\n\nIt defines the loss function to be minimized. Most commonly used values are given below -\n\n* ***reg:squarederror*** : regression with squared loss.\n* ***reg:squaredlogerror***: regression with squared log loss 1/2*(log(pred+1)−log(label+1)) - All input labels are required to be greater than -1.\n* ***reg:logistic*** : logistic regression\n* ***binary:logistic*** : logistic regression for binary classification, output probability\n* ***binary:logitraw***: logistic regression for binary classification, output score before logistic transformation\n* ***binary:hinge*** : hinge loss for binary classification. This makes predictions of 0 or 1, rather than producing probabilities.\n* ***multi:softmax*** : set XGBoost to do multiclass classification using the softmax objective, you also need to set num_class(number of classes)\n* ***multi:softprob*** : same as softmax, but output a vector of ndata nclass, which can be further reshaped to ndata nclass matrix. The result contains predicted probability of each data point belonging to each class.\n\n**3.2 eval_metric(default according to objective)**\n\nThe metric to be used for validation data.The default values are rmse for regression, error for classification and mean average precision for ranking.\nWe can add multiple evaluation metrics.Python users must pass the metrices as list of parameters pairs instead of map.The most common values are given below -\n\n* ***rmse*** : root mean square error\n* ***mae*** : mean absolute error\n* ***logloss*** : negative log-likelihood \n* ***error*** : Binary classification error rate (0.5 threshold). It is calculated as #(wrong cases)/#(all cases). For the predictions, the evaluation will regard the instances with prediction value larger than 0.5 as positive instances, and the others as negative instances.\n* ***merror*** : Multiclass classification error rate. It is calculated as #(wrong cases)/#(all cases).\n* ***mlogloss*** : Multiclass logloss\n* ***auc: Area under*** the curve\n* ***aucpr*** : Area under the PR curve\n\n**3.3 seed(default=0)\n\n* The random number seed.\n* This parameter is ignored in R package, use set.seed() instead.\n* It can be used for generating reproducible results and also for parameter tuning.","metadata":{}},{"cell_type":"markdown","source":"## ML Model - Training\n\n**XGBoost Regressor**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\nmodel = XGBRegressor(gamma=0.1,booster='gblinear',eval_metric='rmse',learning_rate=1.3,\n                     reg_alpha=0.5,reg_lambda=0.5)\n\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T10:13:12.317276Z","iopub.execute_input":"2022-05-01T10:13:12.317992Z","iopub.status.idle":"2022-05-01T10:13:13.061066Z","shell.execute_reply.started":"2022-05-01T10:13:12.317953Z","shell.execute_reply":"2022-05-01T10:13:13.060545Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# plot\nimport matplotlib.pyplot as plt\nfrom xgboost import plot_importance\nplot_importance(model)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T10:31:37.747367Z","iopub.execute_input":"2022-05-01T10:31:37.747635Z","iopub.status.idle":"2022-05-01T10:31:39.085610Z","shell.execute_reply.started":"2022-05-01T10:31:37.747606Z","shell.execute_reply":"2022-05-01T10:31:39.084926Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"predict= model.predict(X_test)\npredict","metadata":{"execution":{"iopub.status.busy":"2022-05-01T10:13:20.103432Z","iopub.execute_input":"2022-05-01T10:13:20.103697Z","iopub.status.idle":"2022-05-01T10:13:20.123680Z","shell.execute_reply.started":"2022-05-01T10:13:20.103667Z","shell.execute_reply":"2022-05-01T10:13:20.123174Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"## Score","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nr2_score(predict, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T10:13:28.002628Z","iopub.execute_input":"2022-05-01T10:13:28.002889Z","iopub.status.idle":"2022-05-01T10:13:28.009454Z","shell.execute_reply.started":"2022-05-01T10:13:28.002860Z","shell.execute_reply":"2022-05-01T10:13:28.008702Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"## Suggestions:-\n* Kaggle - https://www.kaggle.com/pythonkumar\n* GitHub - https://github.com/KumarPython​\n* Twitter - https://twitter.com/KumarPython\n* LinkedIn - https://www.linkedin.com/in/kumarpython/","metadata":{}},{"cell_type":"code","source":"submission=pd.DataFrame({'Id': id,\n                         'SalePrice' : model.predict(test)\n                        })\n# submission\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T09:59:36.828988Z","iopub.execute_input":"2022-05-01T09:59:36.829508Z","iopub.status.idle":"2022-05-01T09:59:36.853286Z","shell.execute_reply.started":"2022-05-01T09:59:36.829471Z","shell.execute_reply":"2022-05-01T09:59:36.852601Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nreg = GradientBoostingRegressor(n_estimators=100,\n                                warm_start=True,max_depth=5,min_impurity_decrease=0.1,max_features='auto',\n                                random_state=0)\nreg.fit(X_train, y_train)\n# print(reg.feature_importances_)\n# print(reg.estimators_)\nreg.score(X_test, y_test)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-01T10:49:51.754058Z","iopub.execute_input":"2022-05-01T10:49:51.754757Z","iopub.status.idle":"2022-05-01T10:49:52.562661Z","shell.execute_reply.started":"2022-05-01T10:49:51.754719Z","shell.execute_reply":"2022-05-01T10:49:52.561933Z"},"trusted":true},"execution_count":87,"outputs":[]}]}
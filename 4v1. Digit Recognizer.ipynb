{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Taking a look at the features"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train['label'].astype('float32')\nX_train = train.drop(['label'], axis=1).astype('int32')\nX_test = test.astype('float32')\nX_train.shape, y_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('dark_background')\nplt.figure(figsize=(10,8))\nplt.xticks(size=20)\nplt.yticks(size=20)\n\nx = sns.countplot(x='label', data=train,palette=['cyan','yellow','pink','b','y','purple','magenta','hotpink','turquoise','lightblue']);\nx.set_xlabel(\"Label\",fontsize=30)\nx.set_ylabel('Count',fontsize=30)\n#sns.plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train/255\nX_test = X_test/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train = X_train.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)\nX_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# One-hot encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\ny_train = to_categorical(y_train, num_classes = 10)\ny_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['label'].head())\ny_train[0:5,:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size = 0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.imshow(X_train[1][:,:,0])\nplt.title(y_train[1].argmax());","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing DL libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout\nfrom keras.models import Sequential,Model\nfrom keras.optimizers import SGD\nfrom keras.callbacks import ModelCheckpoint,LearningRateScheduler\nimport keras\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building a CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building a CNN model\ninput_shape = (28,28,1)\nX_input = Input(input_shape)\n\n# layer 1\nx = Conv2D(64,(3,3),strides=(1,1),name='layer_conv1',padding='same')(X_input)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2),name='maxPool1')(x)\n# layer 2\nx = Conv2D(32,(3,3),strides=(1,1),name='layer_conv2',padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2),name='maxPool2')(x)\n# layer 3\nx = Conv2D(32,(3,3),strides=(1,1),name='conv3',padding='same')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = MaxPooling2D((2,2), name='maxPool3')(x)\n# fc\nx = Flatten()(x)\nx = Dense(64,activation ='relu',name='fc0')(x)\nx = Dropout(0.25)(x)\nx = Dense(32,activation ='relu',name='fc1')(x)\nx = Dropout(0.25)(x)\nx = Dense(10,activation ='softmax',name='fc2')(x)\n\nconv_model = Model(inputs=X_input, outputs=x, name='Predict')\nconv_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Note :\nIn SGD 30 epochs is a reasonable choice to use although it takes a long time to compute.\nAdam optimizer converges quicker. Use one of the following optimizers."},{"metadata":{},"cell_type":"markdown","source":"# Using Adam"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adam optimizer\nconv_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nconv_model.fit(X_train, y_train, epochs=10, batch_size=100, validation_data=(X_cv,y_cv))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using SGD"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# SGD optimizer\nsgd = SGD(lr=0.0005, momentum=0.5, decay=0.0, nesterov=False) \nconv_model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\nconv_model.fit(X_train, y_train, epochs=30, validation_data=(X_cv, y_cv))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_pred = conv_model.predict(X_test)\ny_pred = np.argmax(y_pred,axis=1)\nmy_submission = pd.DataFrame({'ImageId': list(range(1, len(y_pred)+1)), 'Label': y_pred})\nmy_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Test Accuracy\nAdam optimizer (10 epochs, batch size = 100) : 0.98985<br>\nSGD optimizer (12 epochs) : 0.97600"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
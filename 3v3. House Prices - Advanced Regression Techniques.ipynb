{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-03T09:00:01.15235Z","iopub.execute_input":"2022-05-03T09:00:01.153128Z","iopub.status.idle":"2022-05-03T09:00:01.16467Z","shell.execute_reply.started":"2022-05-03T09:00:01.153087Z","shell.execute_reply":"2022-05-03T09:00:01.163504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## In this notebook, I will take a different approach. I will use Concepts like \n1. **Feature Engineering with - LabelEncoder, SimpleImputer, BOX-COX Transfomtion, IsolationForest, RobustScalar**\n2. **Feature Selection with - SelectKBest**\n3. **Normal Equation**\n4. **RMLSE evaluation**\n5. **Feature Importance with - SHAP Values**\n\n## For more traditional approach, (EDA + Excellent Data Viz + XGBoost HyperParameter Tuning + Feature Engineering Tutorial)\nyou may visit:-[https://www.kaggle.com/code/pythonkumar/xgboost-hyperparameters-excellent-plots-acc-91?kernelSessionId=94478268]","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:01.209946Z","iopub.execute_input":"2022-05-03T09:00:01.210913Z","iopub.status.idle":"2022-05-03T09:00:01.214882Z","shell.execute_reply.started":"2022-05-03T09:00:01.21087Z","shell.execute_reply":"2022-05-03T09:00:01.213838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\nId=test['Id']\ntrain\n# test","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:01.280065Z","iopub.execute_input":"2022-05-03T09:00:01.280554Z","iopub.status.idle":"2022-05-03T09:00:01.358666Z","shell.execute_reply.started":"2022-05-03T09:00:01.280505Z","shell.execute_reply":"2022-05-03T09:00:01.357968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Drop some USELESS Columns","metadata":{}},{"cell_type":"code","source":"train=train.drop(columns=['SalePrice','Id'], axis=1)\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:01.359976Z","iopub.execute_input":"2022-05-03T09:00:01.360346Z","iopub.status.idle":"2022-05-03T09:00:01.400506Z","shell.execute_reply.started":"2022-05-03T09:00:01.360317Z","shell.execute_reply":"2022-05-03T09:00:01.39943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=test.drop(columns=['Id'], axis=1)\ntest","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:01.418102Z","iopub.execute_input":"2022-05-03T09:00:01.418382Z","iopub.status.idle":"2022-05-03T09:00:01.455958Z","shell.execute_reply.started":"2022-05-03T09:00:01.418355Z","shell.execute_reply":"2022-05-03T09:00:01.455203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Changing Infinite to Nan","metadata":{}},{"cell_type":"code","source":"pd.set_option('mode.use_inf_as_na', True)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:01.468259Z","iopub.execute_input":"2022-05-03T09:00:01.468568Z","iopub.status.idle":"2022-05-03T09:00:01.47444Z","shell.execute_reply.started":"2022-05-03T09:00:01.468536Z","shell.execute_reply":"2022-05-03T09:00:01.473545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Columns having Null Values","metadata":{}},{"cell_type":"code","source":"null_train=train.columns[train.isnull().any()]\nnull_train","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:01.524835Z","iopub.execute_input":"2022-05-03T09:00:01.525333Z","iopub.status.idle":"2022-05-03T09:00:01.545827Z","shell.execute_reply.started":"2022-05-03T09:00:01.525281Z","shell.execute_reply":"2022-05-03T09:00:01.544737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_test=test.columns[test.isnull().any()]\nnull_test","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:01.575086Z","iopub.execute_input":"2022-05-03T09:00:01.575876Z","iopub.status.idle":"2022-05-03T09:00:01.59321Z","shell.execute_reply.started":"2022-05-03T09:00:01.57582Z","shell.execute_reply":"2022-05-03T09:00:01.592241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Seperate Numerical & Categorical columns","metadata":{}},{"cell_type":"code","source":"num_train = train.select_dtypes(include=['int64','float64','UInt32'])\ncat_train = train.select_dtypes(include=['object','string'])\nnum_train\n# cat_train","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:01.637403Z","iopub.execute_input":"2022-05-03T09:00:01.637691Z","iopub.status.idle":"2022-05-03T09:00:01.673779Z","shell.execute_reply.started":"2022-05-03T09:00:01.637663Z","shell.execute_reply":"2022-05-03T09:00:01.672715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_test = test.select_dtypes(include=['int64','float64','UInt32'])\ncat_test = test.select_dtypes(include=['object','string'])\n# num_test\ncat_test","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:01.708473Z","iopub.execute_input":"2022-05-03T09:00:01.708752Z","iopub.status.idle":"2022-05-03T09:00:01.749276Z","shell.execute_reply.started":"2022-05-03T09:00:01.708723Z","shell.execute_reply":"2022-05-03T09:00:01.748409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling Categorical Features\n\nMost ML Models cannot work with non-numeric values, so we need to apply some form of transformation of these categorical values into numeric labels and then applying some encoding scheme on these values.\n\n* Nominal attributes consist of discrete categorical values with no notion or sense of order amongst them.\n* Ordinal attributes are categorical attributes with a sense of order amongst the values.","metadata":{}},{"cell_type":"code","source":"# Label Encoding - This transformer should be used to encode 1 COLUMN at a Time\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\nfor cat in cat_train:\n    train[cat]=le.fit_transform(train[cat])\n    \ntrain","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:01.765715Z","iopub.execute_input":"2022-05-03T09:00:01.765993Z","iopub.status.idle":"2022-05-03T09:00:01.847087Z","shell.execute_reply.started":"2022-05-03T09:00:01.765964Z","shell.execute_reply":"2022-05-03T09:00:01.845938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for cat in cat_test:\n    test[cat]=le.fit_transform(test[cat])\ntest","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:01.84917Z","iopub.execute_input":"2022-05-03T09:00:01.84962Z","iopub.status.idle":"2022-05-03T09:00:01.928358Z","shell.execute_reply.started":"2022-05-03T09:00:01.849538Z","shell.execute_reply":"2022-05-03T09:00:01.927744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling Missing Values\n\nMissing values are one of the most common problems you can encounter when you try to prepare your data for machine learning. The reason for the missing values might be human errors,interruptions in the data flow, privacy concerns, and so on. Whatever is the reason, missing values affect the performance of the machine learning models.","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nimp = SimpleImputer(strategy='most_frequent')\n\ntrain[null_train] = imp.fit_transform(train[null_train])\ntrain.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:01.929765Z","iopub.execute_input":"2022-05-03T09:00:01.930163Z","iopub.status.idle":"2022-05-03T09:00:01.960902Z","shell.execute_reply.started":"2022-05-03T09:00:01.930132Z","shell.execute_reply":"2022-05-03T09:00:01.959987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[null_test] = imp.fit_transform(test[null_test])\ntest.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:01.963013Z","iopub.execute_input":"2022-05-03T09:00:01.963548Z","iopub.status.idle":"2022-05-03T09:00:01.99505Z","shell.execute_reply.started":"2022-05-03T09:00:01.9635Z","shell.execute_reply":"2022-05-03T09:00:01.994467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling Outliers\nIn statistics, an outlier is a data point that differs significantly from other observations. An outlier may be due to variability in the measurement or it may indicate experimental error; the latter are sometimes excluded from the data set. An outlier can cause serious problems in statistical analyses.","metadata":{}},{"cell_type":"code","source":"# Using Isolation Forest\nfrom sklearn.ensemble import IsolationForest\niso = IsolationForest(contamination=0.3)\n\nout = iso.fit_predict(train)\n\n# select all rows that are not outliers\ntrain[out != -1]\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:02.060081Z","iopub.execute_input":"2022-05-03T09:00:02.061014Z","iopub.status.idle":"2022-05-03T09:00:02.6126Z","shell.execute_reply.started":"2022-05-03T09:00:02.060967Z","shell.execute_reply":"2022-05-03T09:00:02.611642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out = iso.fit_predict(test)\n\n# select all rows that are not outliers\ntest[out != -1]\ntest","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:02.614842Z","iopub.execute_input":"2022-05-03T09:00:02.615643Z","iopub.status.idle":"2022-05-03T09:00:03.156581Z","shell.execute_reply.started":"2022-05-03T09:00:02.615593Z","shell.execute_reply":"2022-05-03T09:00:03.155643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Box Cox Transformation - Both Discreet & Continuous Values\n\nA Box Cox transformation is a transformation of non-normal dependent variables into a normal shape. Normality is an important assumption for many statistical techniques; if your data isn’t normal, applying a Box-Cox means that you are able to run a broader number of tests.","metadata":{}},{"cell_type":"code","source":"# from scipy.stats import skew\n# from scipy.special import boxcox1p\n# from scipy.stats import boxcox_normmax\n\n# # Fixing Skewness\n# for feat in num_train:\n#         train[feat] = boxcox1p(train[feat], boxcox_normmax(train[feat] + 1))\n# train","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:03.157804Z","iopub.execute_input":"2022-05-03T09:00:03.158081Z","iopub.status.idle":"2022-05-03T09:00:03.162588Z","shell.execute_reply.started":"2022-05-03T09:00:03.158016Z","shell.execute_reply":"2022-05-03T09:00:03.161502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from scipy.stats import skew\n# from scipy.special import boxcox1p\n# from scipy.stats import boxcox_normmax\n\n# # Fixing Skewness\n# for feat in num_test:\n#         test[feat] = boxcox1p(test[feat], boxcox_normmax(test[feat] + 1))\n# test","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:03.165257Z","iopub.execute_input":"2022-05-03T09:00:03.165685Z","iopub.status.idle":"2022-05-03T09:00:03.183904Z","shell.execute_reply.started":"2022-05-03T09:00:03.16564Z","shell.execute_reply":"2022-05-03T09:00:03.182691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting X & y","metadata":{}},{"cell_type":"code","source":"train1=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ny=train1['SalePrice']\nX=train\n# y\nX","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:03.184895Z","iopub.execute_input":"2022-05-03T09:00:03.185125Z","iopub.status.idle":"2022-05-03T09:00:03.252486Z","shell.execute_reply.started":"2022-05-03T09:00:03.185098Z","shell.execute_reply":"2022-05-03T09:00:03.251356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Test Split\n\nIt splits the train data into 4 parts, X_train, X_test, y_train, y_test.\n\nX_train, y_train first used to train the algorithm.\nX_test is used in that trained algorithms to predict outcomes.\nOnce we get the outcomes, we compare it with y_test","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n# X_train\n# X_test\n# y_train\ny_test","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:03.253819Z","iopub.execute_input":"2022-05-03T09:00:03.254048Z","iopub.status.idle":"2022-05-03T09:00:03.266451Z","shell.execute_reply.started":"2022-05-03T09:00:03.254021Z","shell.execute_reply":"2022-05-03T09:00:03.265352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **XGBoost Regressor - Model & Training** \n\nSupport Vector Regression is a supervised learning algorithm that is used to predict discrete values. Support Vector Regression uses the same principle as the SVMs. The basic idea behind SVR is to find the best fit line. In SVR, the best fit line is the hyperplane that has the maximum number of poi","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\nmodel = XGBRegressor(colsample_bytree=0.4,\n                 gamma=0,                 \n                 learning_rate=0.07,\n                 max_depth=3,\n                 min_child_weight=1.5,\n                 n_estimators=10000,                                                                    \n                 reg_alpha=0.75,\n                 reg_lambda=0.45,\n                 subsample=0.6,\n                 seed=42)\n\nmodel.fit(X_train, y_train)\n\nmodel.get_params()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:03.267688Z","iopub.execute_input":"2022-05-03T09:00:03.268899Z","iopub.status.idle":"2022-05-03T09:00:37.468361Z","shell.execute_reply.started":"2022-05-03T09:00:03.268839Z","shell.execute_reply":"2022-05-03T09:00:37.467772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting from XGB Model","metadata":{}},{"cell_type":"code","source":"pred=model.predict(X_test)\npred","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:37.469474Z","iopub.execute_input":"2022-05-03T09:00:37.469854Z","iopub.status.idle":"2022-05-03T09:00:37.510644Z","shell.execute_reply.started":"2022-05-03T09:00:37.469826Z","shell.execute_reply":"2022-05-03T09:00:37.509987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scoring the Model","metadata":{}},{"cell_type":"code","source":"model.score(X_test,pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:37.511969Z","iopub.execute_input":"2022-05-03T09:00:37.512436Z","iopub.status.idle":"2022-05-03T09:00:37.549584Z","shell.execute_reply.started":"2022-05-03T09:00:37.512385Z","shell.execute_reply":"2022-05-03T09:00:37.548852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\n\n# get importance\nimportance = model.feature_importances_\n\n# summarize feature importance\nfor i,v in enumerate(importance):\n    print('Feature: %0d, Score: %.5f' % (i,v))","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:37.554616Z","iopub.execute_input":"2022-05-03T09:00:37.555218Z","iopub.status.idle":"2022-05-03T09:00:37.582457Z","shell.execute_reply.started":"2022-05-03T09:00:37.555178Z","shell.execute_reply":"2022-05-03T09:00:37.581538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## In this notebook, I am using a different approach. I will use Concepts like \n1. **Feature Engineering with - LabelEncoder, SimpleImputer, BOX-COX Transfomtion, IsolationForest, RobustScalar**\n2. **Feature Selection with - SelectKBest**\n3. **Normal Equation**\n4. **RMLSE evaluation**\n5. **Feature Importance with - SHAP Values**\n\n## For more traditional approach, (EDA + Excellent Data Viz + XGBoost HyperParameter Tuning + Feature Engineering Tutorial)\nyou may visit:-[https://www.kaggle.com/code/pythonkumar/xgboost-hyperparameters-excellent-plots-acc-91?kernelSessionId=94478268]","metadata":{}},{"cell_type":"markdown","source":"# Feature Selection - for Normal Eqn\n\nIrrelevant or partially relevant features can negatively impact model performance.Feature Selection is the process where you automatically or manually select those features which contribute most to your prediction variable or output in which you are interested in.\n* **Reduces Overfitting:** Less redundant data means less opportunity to make decisions based on noise.\n* **Improves Accuracy:** Less misleading data means modeling accuracy improves.\n* **Reduces Training Time:** fewer data points reduce algorithm complexity and algorithms train faster.","metadata":{}},{"cell_type":"code","source":"# # Select features according to the k highest scores.\n# from sklearn.feature_selection import SelectKBest, chi2\n\n# select = SelectKBest(chi2, k=20)\n\n# ntrain=select.fit_transform(X,y)\n# print(ntrain.shape)\n# ntrain=pd.DataFrame(ntrain)\n# ntrain","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:37.583799Z","iopub.execute_input":"2022-05-03T09:00:37.584035Z","iopub.status.idle":"2022-05-03T09:00:37.587785Z","shell.execute_reply.started":"2022-05-03T09:00:37.584006Z","shell.execute_reply":"2022-05-03T09:00:37.586971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imp=select.get_feature_names_out(input_features=X.columns)\n# imp","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:37.589077Z","iopub.execute_input":"2022-05-03T09:00:37.589293Z","iopub.status.idle":"2022-05-03T09:00:37.605087Z","shell.execute_reply.started":"2022-05-03T09:00:37.589265Z","shell.execute_reply":"2022-05-03T09:00:37.603876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Select same features as the TRAIN set features according to the k highest scores.\n# test=pd.DataFrame(test)\n# ntest=test[imp]\n# print(ntest.shape)\n# ntest","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:37.606457Z","iopub.execute_input":"2022-05-03T09:00:37.606949Z","iopub.status.idle":"2022-05-03T09:00:37.622221Z","shell.execute_reply.started":"2022-05-03T09:00:37.606904Z","shell.execute_reply":"2022-05-03T09:00:37.621226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting X & y again - for Normal Eqn","metadata":{}},{"cell_type":"code","source":"# ny=train1['SalePrice'].iloc[29:49]\n# nX=ntrain.iloc[29:49]\n# # nX=np.append(np.ones((20,1)),ntrain[:20],axis=1)\n# # ny\n# nX.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:37.623695Z","iopub.execute_input":"2022-05-03T09:00:37.623947Z","iopub.status.idle":"2022-05-03T09:00:37.640024Z","shell.execute_reply.started":"2022-05-03T09:00:37.623917Z","shell.execute_reply":"2022-05-03T09:00:37.639006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Normal Equation**\n\nNormal Equation is an analytical approach to Linear Regression with a Least Square Cost Function. We can directly find out the value of θ without using Gradient Descent.","metadata":{}},{"cell_type":"code","source":"# def normal_equation(X, Y):\n# #     lam=0.1*np.eye(20)\n#     theta = np.dot(np.linalg.inv(np.dot(X.T,X)),np.dot(X.T,Y))\n#     return theta\n\n# normal_equation(nX,ny)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:37.641296Z","iopub.execute_input":"2022-05-03T09:00:37.641546Z","iopub.status.idle":"2022-05-03T09:00:37.656132Z","shell.execute_reply.started":"2022-05-03T09:00:37.641517Z","shell.execute_reply":"2022-05-03T09:00:37.655213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting from Normal Eqn","metadata":{}},{"cell_type":"code","source":"# beta=normal_equation(nX,ny)\n# predict=np.dot(X_test,beta.T)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:37.657883Z","iopub.execute_input":"2022-05-03T09:00:37.658189Z","iopub.status.idle":"2022-05-03T09:00:37.673773Z","shell.execute_reply.started":"2022-05-03T09:00:37.658148Z","shell.execute_reply":"2022-05-03T09:00:37.672889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RMSE - Root Mean Squared Error","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nrmse=mean_squared_error(y_test, pred,squared=False)\nrmse","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:37.675929Z","iopub.execute_input":"2022-05-03T09:00:37.676178Z","iopub.status.idle":"2022-05-03T09:00:37.694259Z","shell.execute_reply.started":"2022-05-03T09:00:37.676148Z","shell.execute_reply":"2022-05-03T09:00:37.693387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## In this notebook, I am using a different approach. I will use Concepts like \n1. **Feature Engineering with - LabelEncoder, SimpleImputer, BOX-COX Transfomtion, IsolationForest, RobustScalar**\n2. **Feature Selection with - SelectKBest**\n3. **Normal Equation**\n4. **RMLSE evaluation**\n5. **Feature Importance with - SHAP Values**\n\n## For more traditional approach, (EDA + Excellent Data Viz + XGBoost HyperParameter Tuning + Feature Engineering Tutorial)\nyou may visit:-[https://www.kaggle.com/code/pythonkumar/xgboost-hyperparameters-excellent-plots-acc-91?kernelSessionId=94478268]","metadata":{}},{"cell_type":"markdown","source":"# **Feature Importance - Shap Values**\n\nThe goal of SHAP is to explain the prediction of an instance x by computing the contribution of each feature to the prediction. \n\nSHAP values interpret the impact of having a certain value for a given feature in comparison to the prediction we'd make if that feature took some baseline value.","metadata":{}},{"cell_type":"code","source":"# import shap\n# explainer = shap.TreeExplainer(model)\n# shap_values = explainer.shap_values(X)\n\n# # Waterfall Plot\n# shap.plots.waterfall(shap_values,max_display=20)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:37.695547Z","iopub.execute_input":"2022-05-03T09:00:37.695788Z","iopub.status.idle":"2022-05-03T09:00:37.707592Z","shell.execute_reply.started":"2022-05-03T09:00:37.69576Z","shell.execute_reply":"2022-05-03T09:00:37.706483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X)\n\n# Summary Plot\nshap.summary_plot(shap_values, features=X, feature_names=X.columns)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:37.709188Z","iopub.execute_input":"2022-05-03T09:00:37.709527Z","iopub.status.idle":"2022-05-03T09:00:50.40933Z","shell.execute_reply.started":"2022-05-03T09:00:37.709484Z","shell.execute_reply":"2022-05-03T09:00:50.408648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\nexplainer = shap.TreeExplainer(model)\n\n# Get expected value and shap values array\nexpected_value = explainer.expected_value\nshap_array = explainer.shap_values(X)\n\n# Bar Summary Plot\nshap.summary_plot(shap_values, features=X, feature_names=X.columns, plot_type='bar')","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:00:50.410348Z","iopub.execute_input":"2022-05-03T09:00:50.41103Z","iopub.status.idle":"2022-05-03T09:01:02.548736Z","shell.execute_reply.started":"2022-05-03T09:00:50.410995Z","shell.execute_reply":"2022-05-03T09:01:02.54803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\nexplainer = shap.TreeExplainer(model)\n\n# Get expected value and shap values array\nexpected_value = explainer.expected_value\nshap_array = explainer.shap_values(X)\n\n# Descion plot\nshap.decision_plot(expected_value, shap_array[0:10],feature_names=list(X.columns))","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:01:02.550022Z","iopub.execute_input":"2022-05-03T09:01:02.550742Z","iopub.status.idle":"2022-05-03T09:01:14.76244Z","shell.execute_reply.started":"2022-05-03T09:01:02.550695Z","shell.execute_reply":"2022-05-03T09:01:14.76141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import shap\n# explainer = shap.TreeExplainer(model)\n\n# # Get expected value and shap values array\n# # expected_value = explainer.expected_valuAe\n# shap_array = explainer.shap_values(X)\n\n# # Beeswarm Plot\n# shap.plots.beeswarm(shap_values, color=plt.get_cmap(\"cool\"))","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:02:26.134984Z","iopub.execute_input":"2022-05-03T09:02:26.135306Z","iopub.status.idle":"2022-05-03T09:02:37.781156Z","shell.execute_reply.started":"2022-05-03T09:02:26.135273Z","shell.execute_reply":"2022-05-03T09:02:37.780042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shap\n# explainer = shap.TreeExplainer(model)\n\n# # Get expected value and shap values array\n# expected_value = explainer.expected_value\n# shap_array = explainer.shap_values(X)\n\n# # Force Plot\n# shap.force_plot(expected_value, matplotlib=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:02:55.77139Z","iopub.execute_input":"2022-05-03T09:02:55.77223Z","iopub.status.idle":"2022-05-03T09:03:07.43626Z","shell.execute_reply.started":"2022-05-03T09:02:55.772179Z","shell.execute_reply":"2022-05-03T09:03:07.434944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shap\n# explainer = shap.TreeExplainer(model)\n# shap_values = explainer.shap_values(X)\n\n# # Heatmap Plot\n# shap.plots.heatmap(shap_values, max_display=12)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:03:38.083242Z","iopub.execute_input":"2022-05-03T09:03:38.084272Z","iopub.status.idle":"2022-05-03T09:03:50.046984Z","shell.execute_reply.started":"2022-05-03T09:03:38.084213Z","shell.execute_reply":"2022-05-03T09:03:50.045684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission=pd.DataFrame({'Id': Id,\n                         'SalePrice' : model.predict(test)\n                        })\n# submission\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T09:01:14.800295Z","iopub.execute_input":"2022-05-03T09:01:14.800739Z","iopub.status.idle":"2022-05-03T09:01:14.911734Z","shell.execute_reply.started":"2022-05-03T09:01:14.800707Z","shell.execute_reply":"2022-05-03T09:01:14.911123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}